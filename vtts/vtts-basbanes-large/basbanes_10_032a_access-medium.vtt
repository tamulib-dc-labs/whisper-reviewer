WEBVTT

00:04.199 --> 00:15.960
So how do you feel confident making predictions about a hundred years from now?

00:27.421 --> 00:28.603
Thank you very much.

00:31.418 --> 00:55.065
Well, no one has a perfect crystal ball with regard to the future, but I have tried to bring some structure without methodology and discipline to the art of making technological predictions.

00:56.667 --> 00:59.670
And the predictions I made

01:00.157 --> 01:01.779
in a book I wrote about 12 years ago.

01:02.240 --> 01:07.488
It turned out rather well regarding the 1990s.

01:07.949 --> 01:12.996
That was the age of intelligent machines.

01:13.036 --> 01:13.297
Right.

01:15.800 --> 01:18.224
The next one.

01:18.244 --> 01:23.251
Those are some of the connections I made.

01:26.556 --> 01:29.100
There are several common mistakes that people make

01:29.688 --> 01:30.869
when looking at the future.

01:30.909 --> 01:36.636
Most people, if you ask them about the 21st century, will give you a comment about 2004.

01:36.656 --> 01:46.047
Most people are really hesitant to push the horizons and understand how different the future will be.

01:46.087 --> 01:55.497
One mistake is to only look at one or two trends, and there are many intersecting trends, and they build on each other.

01:55.518 --> 01:57.720
A second one

01:58.679 --> 02:10.454
He is only looking at one or two iterations of progress in a particular trend and then imagining that progress stops and not realizing that one innovation builds on the next.

02:11.535 --> 02:21.328
And the biggest, I think, failure to understand the future is not understanding the exponential nature of time and the accelerating pace of technological progress.

02:23.370 --> 02:24.872
Technology is accelerating.

02:24.932 --> 02:27.235
I talk about that at length in the beginning of the book.

02:27.940 --> 02:29.683
called the law of accelerating returns.

02:30.764 --> 02:33.428
More will happen in the next 20 years than happened in the last 100.

02:33.708 --> 02:34.990
Quite a bit happened in the last 100.

02:35.811 --> 02:45.085
So very often people, I mean, you read about, I mean, and these are scientists or well-known people who talk about it's going to take 100 years for something to happen.

02:45.125 --> 02:51.434
And indeed, in the past, a particular development may have taken 100 years, but it will only take 15 years in the future.

02:51.454 --> 02:57.002
So when you consider the exponential growth

02:57.725 --> 03:17.973
of technology, the enormous power that these very powerful computers will have, the extent to which they're going to be deeply embedded in our society and civilization, all the different intersecting trends from reverse engineering to the human brain, brain scanning, and the growth of computation and progress in all the different fields of research and computer science, et cetera, et cetera.

03:18.634 --> 03:22.620
You put that all together and it has a pretty formidable effect.

03:23.541 --> 03:26.365
The law of accelerating returns does provide

03:26.935 --> 03:32.081
quantitative measure of the kind of progress we can expect at different points in time.

03:33.423 --> 03:40.872
And I talk about, for example, we're able to shrink the size of our technologies by a certain factor each decade.

03:42.894 --> 03:49.362
The growth of computing power per unit cost has been growing at a very predictable rate.

03:50.263 --> 03:56.571
So we can look at different scanning technologies are getting higher resolution and higher bandwidth at a pretty predictable rate.

03:57.665 --> 04:08.721
So we can get a pretty good idea of the kinds of technologies that would be available at different points in time, the kinds of software capabilities that would be feasible.

04:09.182 --> 04:18.195
I've been watching software development for 35 years and have a sense of how quickly progress is made in different fields.

04:19.376 --> 04:27.368
So you put that all together and you can get a picture of what life would be like, what technology would be like at different points in time.

04:28.276 --> 04:36.407
You know, whether predictions are exact to the year or not is less important than the general trend.

04:38.610 --> 04:54.250
You know, the key threshold event that I see coming, you know, fairly soon in the next century, within, say, three decades, is the emergence of non-biological entities called the machines, but the concept of a machine will have a very different connotation than the 21st century does today.

04:55.023 --> 04:57.767
because today a machine means something simple and formulaic.

04:57.787 --> 04:59.389
Something like that, something like this.

04:59.409 --> 05:01.653
In the future, machines will be more like people.

05:02.634 --> 05:11.286
But nonetheless, machines, non-biological entities, will gain a level of intelligence equal to the flexibility and depth and breadth of human intelligence.

05:12.288 --> 05:18.937
When that happens, they're going to combine that human flexibility and depth with some advantages they already have.

05:19.118 --> 05:19.738
You said they are?

05:19.979 --> 05:22.903
Are they going to do this on their own, or are we going to allow them to do this?

05:25.837 --> 05:29.242
I guess it's a moral question in a way.

05:29.442 --> 05:31.305
There almost seems to be an inevitability to it.

05:31.906 --> 05:32.307
They will.

05:33.108 --> 05:35.471
We're guiding this development now.

05:35.531 --> 05:36.793
It's already a joint effort.

05:36.953 --> 05:40.739
The first computers were designed entirely by humans.

05:41.500 --> 05:46.748
Today, humans give the general design parameters, and most of the stages of development are worked out by a computer.

05:48.130 --> 05:55.641
As we get into the next century, machines, like to say non-biological entities, will be designing their own next generations.

05:56.212 --> 05:57.634
So it's already a collaborative effort.

05:58.676 --> 06:01.020
Machines are not something apart from human civilization.

06:01.060 --> 06:02.603
It's very much part of our civilization.

06:02.623 --> 06:05.407
It's already extending the reach of our bodies and our minds.

06:06.409 --> 06:10.456
And they will literally expand our minds as we go through the next century.

06:10.476 --> 06:12.739
So it's not an alien invasion of intelligent machines.

06:13.641 --> 06:15.244
We're already very intimate with our computers.

06:15.304 --> 06:19.090
If all our computers stopped today, civilization will grind to a halt.

06:19.831 --> 06:22.776
That wasn't true 25 years ago.

06:23.397 --> 06:28.944
We're already putting intelligent machines in our bodies, in our brains, neural implants for Parkinson's disease, for deafness.

06:30.527 --> 06:40.079
There's a chip placed in a paralyzed individual recently who can now communicate wirelessly just through mental, by thinking certain thoughts, communicate with his computer.

06:41.602 --> 06:45.867
We're going to be putting, within 30 years, there'll be ubiquitous use of neural implants.

06:46.849 --> 06:53.117
So it's not a matter that the machines are doing X and the humans are doing Y. It's very much an intimate

06:53.418 --> 07:02.469
It's already true today, and it's going to be a very intimate connection as we go through the next several decades.

07:03.730 --> 07:07.735
So it's very much a man-machine symbiosis.

07:07.875 --> 07:14.603
But the premise has always been that the machine is created to serve man, mankind, right?

07:14.783 --> 07:15.804
Serve and to extent.

07:15.905 --> 07:16.645
And to extent.

07:16.665 --> 07:19.729
So what you're projecting here, it seems to me, is

07:20.198 --> 07:25.283
equal status and a lot of equals.

07:25.303 --> 07:28.326
Right, but I mean, there's not going to be a clear distinction between human and machine.

07:28.386 --> 07:45.403
I mean, you will have, first of all, very commonly humans who have intelligent machines in their bodies and brains, and ultimately that non-biological portion of the brain is going to grow because non-biological computation is growing exponentially.

07:45.423 --> 07:46.704
I mean, it's doubling every year.

07:46.764 --> 07:48.906
The biological

07:49.308 --> 07:54.875
our biological intelligence is relatively at a standstill compared to that.

07:55.456 --> 07:56.698
It's really not developing at all.

07:57.719 --> 08:02.745
So as we start to put these intelligent machines in our brains, which won't necessarily require surgery.

08:02.785 --> 08:04.688
I mean, they'll travel through our bloodstream.

08:04.708 --> 08:10.275
We'll have microscopic computers that are ultimately of human brain capacity.

08:11.797 --> 08:16.463
So we'll have a non-biological aspect to our bodies and brains

08:16.915 --> 08:18.977
that aspect will grow exponentially.

08:18.997 --> 08:21.420
So ultimately, it'll become dominant.

08:23.122 --> 08:25.544
But these will still claim to be humans.

08:25.804 --> 08:32.912
You'll also have other entities that are non-biological, that are completely non-biological, but that are copies of human brains.

08:33.913 --> 08:45.285
Within 30 years, you'll be able to copy my brain and note down every single relevant detail, every synaptic cleft, every neurotransmitter strength, every inter-neuronal connection,

08:45.822 --> 08:52.549
and basically reproduce precisely that whole process of Ray Kurzweil's brain in a neural computer.

08:54.071 --> 08:59.396
Copy is a scary word, isn't it?

08:59.596 --> 09:00.517
We talk about copies.

09:01.038 --> 09:04.041
Are you using it in the clone sense?

09:04.682 --> 09:08.485
The duplication sense, I wonder?

09:09.567 --> 09:12.910
Not duplication atom by atom, but duplication in terms of

09:13.582 --> 09:18.366
all of the functionality of the human brain as it pertains to thinking.

09:20.549 --> 09:21.389
Take it as an analogy.

09:21.409 --> 09:23.371
I mean, they're creating now an artificial pancreas.

09:24.112 --> 09:27.735
Well, it's not built out of pancreatic cells.

09:27.835 --> 09:35.743
It's, in fact, using a different methodology, but it will, just like the real pancreas, perform a function that's similar.

09:35.763 --> 09:41.428
It will monitor in real time the blood and monitor it for insulin glucose levels,

09:41.948 --> 09:48.516
and then create and administer glucose in a continuous fashion like a real pancreas.

09:48.556 --> 09:52.401
Well, it's built very differently than the human brain, but it performs a similar function.

09:53.243 --> 10:00.332
We're going to create analogs of human neurons that are not biological entities.

10:01.453 --> 10:09.964
Much of the complexity of a human neuron is for its own structural support, its own attrition, its own reproduction, its own biological life processes.

10:10.366 --> 10:15.653
It performs certain functions as an information processing entity that we can recreate.

10:15.713 --> 10:16.735
In fact, we've already done that.

10:16.775 --> 10:24.285
We've already created chips that recreate precisely substantial clusters of hundreds of human neurons.

10:25.167 --> 10:28.271
And these are, you can call them computers, but they're very different than today's computers.

10:28.291 --> 10:28.952
They're not digital.

10:29.012 --> 10:30.354
They're digital and analog.

10:30.394 --> 10:31.656
They're massively parallel.

10:32.457 --> 10:39.867
And these are circuits that precisely reproduce exactly what those neurons do, not in terms of moving blood around, but in terms of its

10:40.589 --> 10:42.872
information processing capability.

10:43.874 --> 10:48.020
And we can look inside my brain today and see individual nerve cells.

10:48.180 --> 10:49.142
We can see them fire.

10:49.182 --> 10:54.069
Those scanning technologies are also getting more powerful with each generation.

10:54.089 --> 10:56.813
The next generation will be able to see the connections between the neurons.

10:57.574 --> 11:02.762
A future generation will be able to see the neurotransmitter strengths, which are the site of human learning.

11:03.723 --> 11:08.250
And it's a conservative statement to say that 30 years from now, we would be able to look inside my brain

11:08.652 --> 11:11.856
and see every relevant detail as it pertains to thinking.

11:13.418 --> 11:24.192
The state of my memory, which is hundreds of trillions of neurotransmitter strength levels, every synaptic clef, and record all that in a big database.

11:24.372 --> 11:26.274
It's trillions of bytes of information.

11:26.795 --> 11:33.784
And then basically recreate that process, including the state of my memory and all my skills and everything that makes up my personality.

11:33.984 --> 11:36.988
Be able to translate the data that's in there?

11:37.424 --> 11:39.306
Will it be able to translate the data?

11:39.426 --> 11:41.169
Or is this going to show blocks of data?

11:41.189 --> 11:47.517
It's actually going to be able to... It's not translated, it's going to basically recreate an entity that is operating the same way.

11:47.537 --> 11:52.062
It's going to copy it as a... It's going to copy those processes precisely.

11:52.543 --> 11:57.109
Is there some way to read, you know, the... To understand how it works?

11:57.369 --> 12:03.376
No, to take all of these thoughts in your brain and to get a printout as what this thought is.

12:03.476 --> 12:07.161
You know, these are these words... That's not... That's actually not so trivial...

12:07.934 --> 12:08.354
to do.

12:09.756 --> 12:21.289
We could copy my brain without necessarily understanding the principles of its operation or how it works or what thoughts it's thinking, but just copy it as a massive amount of data.

12:21.329 --> 12:23.571
Would it all be zeros and ones, basically?

12:23.591 --> 12:25.934
Well, it's actually not digital.

12:26.354 --> 12:26.915
It's not digital.

12:26.935 --> 12:31.760
It's analog, but we can still copy it and reproduce it.

12:33.182 --> 12:36.085
And we would then have another entity

12:36.672 --> 12:41.260
that operates the same way as my brain.

12:41.300 --> 12:49.975
And since it has a copy of my memories and skills, it would be very much like Ray Kurzweil.

12:49.995 --> 12:57.288
I'd also be able to give him a body using nanotechnology.

12:58.309 --> 13:01.515
So this new Ray Kurzweil would think that he was me because he'd have

13:01.883 --> 13:03.825
the same memories, he would say.

13:03.885 --> 13:06.528
Would he be fixed in place in terms of age?

13:06.568 --> 13:11.854
You know, the very last words that you use in your timeline is that aging as we know it.

13:11.954 --> 13:17.360
I'm paraphrasing here, but life expectancy is no longer a viable term in relation to intelligent people.

13:17.380 --> 13:17.500
Right.

13:17.520 --> 13:31.215
Well, this new Ray Kurzweil, since he would be built using a new thinking medium, has a shot at a form of immortality, so long as he's careful to make frequent backup copies.

13:31.651 --> 13:36.418
I mean, there's actual real information in our brains, and it's trillions of bytes of information.

13:37.058 --> 13:38.641
And when our hardware crashes, that's it.

13:38.681 --> 13:39.862
That information dies.

13:39.902 --> 13:40.884
We don't preserve it.

13:43.628 --> 13:54.502
One of the advantages of machine intelligence is that the state of memory of a non-biological entity can be captured and retained and preserved and recreated.

13:55.644 --> 13:57.066
Computers can share their knowledge.

13:57.086 --> 13:59.970
If I spend years learning French, I can't just download that to you.

14:00.524 --> 14:01.525
But machines can do that.

14:01.565 --> 14:06.190
They can take the state of their understanding and knowledge and just download it to another machine.

14:06.811 --> 14:13.879
So when one machine learns something, it can transfer that knowledge and insight to trillions of other machines instantly.

14:15.140 --> 14:20.146
So ultimately, all of these non-biological entities can be a master of all human knowledge.

14:20.166 --> 14:23.470
They could have read all of human literature and mastered it all.

14:25.372 --> 14:26.493
They appreciate it, though.

14:26.513 --> 14:28.135
That's the question.

14:29.060 --> 14:33.506
Yes, I mean, because these are going to be recreations of human intelligence.

14:33.546 --> 14:41.458
So they're going to be human-like, and they're going to have human opinions and human emotional reactions.

14:42.039 --> 14:43.120
They'll be just like humans.

14:43.320 --> 14:45.263
Some of them will be copies of specific humans.

14:45.323 --> 14:55.738
Some will be, I think, a more likely scenario is they'll be copies in general of human intelligence, but changed in certain, modified in certain ways.

14:55.858 --> 14:58.442
The point being what, though, just out of curiosity?

14:58.574 --> 15:04.663
The point being that this is the best example we have of an intelligent entity.

15:05.504 --> 15:18.243
So reverse engineering the human brain, understanding how it works, and then emulating the intelligence of human beings in a non-biological entity is the best way to create an intelligent entity.

15:19.505 --> 15:27.096
And this is the whole thrust of our technological progress, is creating...

15:27.802 --> 15:30.285
machines that are intelligent.

15:30.305 --> 15:31.807
To serve us, though, generally.

15:32.809 --> 15:34.831
To expand our civilization.

15:34.871 --> 15:37.194
I mean, this is going to be part of human civilization.

15:37.234 --> 15:40.018
This is kind of the next step in evolution.

15:40.258 --> 15:47.648
So this whole discussion that I've been following for the last couple of years about books and libraries, it really... I know you're totally trivial, isn't it?

15:47.728 --> 15:50.011
It's irrelevant, it seems to me.

15:50.031 --> 15:57.741
Well, it's one step in the process of transferring kind of our natural world into...

16:00.455 --> 16:05.141
into a technological substrate.

16:05.221 --> 16:11.368
I mean, books, that's fairly soon on the horizon.

16:13.211 --> 16:14.772
So there's no doubt in your mind about that.

16:14.813 --> 16:23.223
I mean, all of the debate going on about the future of the codex and the printed book, I would sense that it probably amuses you when you see these debates going on.

16:23.243 --> 16:27.508
Well, I mean, I talked about the life cycle of

16:34.002 --> 16:35.004
of the technology.

16:38.289 --> 16:52.230
And I talk about the different stages, and one stage is called the pretenders, where an upstart threatens to eclipse the older technologies.

16:52.290 --> 17:02.946
Enthusiasts prematurely predict victory while providing some benefits to new technologies found to be missing as a key element of functionality and quality, when it indeed fails to dislodge the established order of the technology conservatives.

17:03.550 --> 17:09.317
Take this as evidence that the original approach will indeed live forever, but this is usually short-lived to victory for the aging technology.

17:11.179 --> 17:14.563
And another example is a print book, a rather mature technology today.

17:14.603 --> 17:19.068
It's now in the stage of the Pretenders with the software-based virtual book as the Pretender.

17:19.889 --> 17:27.297
Lacking the resolution, contrast, lack of flick, and other visual quality of paper, the current generation of virtual books does not have the capability of displacing paper-based publications.

17:27.918 --> 17:34.184
But this victory will be short-lived as future generations of computer displays succeed in providing a fully satisfactory alternative to paper.

17:35.165 --> 17:39.088
And I've seen displays in laboratories that are really of the quality of paper.

17:40.410 --> 17:41.170
They're coming.

17:41.190 --> 17:42.712
Well, I mean, is it going to be like this?

17:42.732 --> 17:43.593
Are you going to turn a page?

17:43.613 --> 17:47.596
And I've seen the book, the e-book that they have over at the MIT media level.

17:47.616 --> 17:48.457
Yeah, but it's something crude.

17:49.298 --> 17:53.241
And it's going to be each page is like a screen, and it has a texture of paper, I guess.

17:53.261 --> 17:54.403
So that's how they're designing it.

17:54.423 --> 17:55.984
They still haven't got it yet.

17:56.403 --> 17:57.425
That's what they're projecting.

17:57.445 --> 17:58.546
I wonder if they're missing the point.

17:58.606 --> 18:04.395
Why are they trying to replicate the shape and the heft in the form of a printed book?

18:05.677 --> 18:09.502
I think you're suggesting a hundred years from now, this is just going to be totally history.

18:09.522 --> 18:16.172
A hundred years from now, we'll be able to bypass this kind of language, but it's a step on the way.

18:16.252 --> 18:21.300
Ten years from now, everyone's going to be carrying around computers of this size or less.

18:21.340 --> 18:22.281
They'll be very thin.

18:23.243 --> 18:25.105
The screens will be extremely high quality.

18:25.145 --> 18:26.207
They'll be wireless.

18:26.845 --> 18:34.956
So you can just, you know, download any kind of information, music, books, movies, right to your little notebook computer.

18:34.976 --> 18:37.138
But the notebook computer won't be a six-pound hefty thing.

18:37.279 --> 18:38.720
We'll run out of gas in two hours.

18:39.081 --> 18:41.844
No, we're making a lot of progress in batteries.

18:41.885 --> 18:44.408
But it'll be, you know, it weighs six ounces.

18:44.468 --> 18:45.389
It'll be this size.

18:46.330 --> 18:47.732
And you'll be able to read on it.

18:47.772 --> 18:49.835
It'll be the same quality as paper.

18:50.295 --> 18:51.918
People really will go away from paper.

18:53.139 --> 18:56.143
Over the next decade, yeah.

18:57.541 --> 18:59.744
You didn't predict that in your last book, though, did you?

19:01.405 --> 19:02.527
Yeah, no, I did talk about that.

19:02.907 --> 19:04.769
Did you predict that it would be gone in 10 years?

19:05.971 --> 19:24.452
I think that my predictions there were pretty much on track with what I would predict now, that paper would not be obsolete by the end of the 1990s, but as we go to the first decade of the next century, displays will begin to displace paper.

19:24.472 --> 19:25.253
But in terms of

19:25.908 --> 19:36.219
But intelligent machines is the whole thrust of our technology, and it's not one phenomenon happening in many different places in many different ways.

19:36.839 --> 19:39.041
Machine is really the word of choice for you.

19:39.802 --> 19:45.228
The word computer, I guess, has had its specific time.

19:45.248 --> 19:47.850
It's kind of an inequitism now, is that right?

19:47.870 --> 19:50.413
Well, I do use it in the subtitle.

19:50.866 --> 19:53.870
But in the conversation you've been talking about machines.

19:53.890 --> 20:01.539
Right, because I'm sensitive to people who have a conception of computer as something similar to the architecture of today's computers.

20:02.760 --> 20:19.320
And a lot of the criticism of artificial intelligence is a criticism of a specific way of building a machine, which is programming it through logical rules, sort of spoon-feeding every little bit of knowledge in a logical structure.

20:19.520 --> 20:25.306
Then the claim is, and then the assertion is, or the criticism is, you can't build something of human-level intelligence that way.

20:27.288 --> 20:27.929
And that's true.

20:27.949 --> 20:29.110
I mean, I agree with that.

20:29.510 --> 20:31.152
But that's not the only way to build a machine.

20:31.212 --> 20:33.314
There's an assumption that computers have to be that way.

20:34.315 --> 20:37.499
And we can build computers the same way the human brain is built.

20:37.539 --> 20:40.242
The human brain is a physical entity.

20:40.262 --> 20:42.644
It's a very complex one, but it's not infinitely complex.

20:43.345 --> 20:45.527
We already understand how substantial

20:46.098 --> 20:49.761
clusters of neurons work, and the brain is made up of 100 billion neurons.

20:49.861 --> 20:52.524
It's not a number that's beyond our fascinating.

20:52.544 --> 20:55.527
We have devices today that have hundreds of billions of things in them.

20:56.528 --> 20:58.930
We can manage that level of complexity.

21:00.211 --> 21:05.596
The human brain combines digital and analog methods, but we can do that in machines.

21:05.716 --> 21:09.499
It's massively parallel, and there's 100 trillion calculations going on at the same time.

21:10.360 --> 21:12.402
And it's not programmed with logical rules.

21:12.442 --> 21:15.565
We have less than a million neurons that are devoted to sort of rational thinking.

21:16.068 --> 21:30.401
most of our brain is devoted to pattern recognition, which is a sort of chaotic process where you have the unpredictable interaction of millions of little processes going on simultaneously, and a solution kind of emerges in a self-organizing way.

21:30.441 --> 21:36.827
And it's a certain paradigm that, in fact, I've been using in my work with pattern recognition.

21:37.147 --> 21:45.535
We can build machines that use these sort of complexity theory methods where you have the interplay of lots of parallel processes

21:46.038 --> 21:48.602
And a solution emerges from their interaction.

21:49.323 --> 21:51.506
And that is how we're going to be building machines.

21:51.546 --> 21:55.451
And we're going to be building them guided by our insights into the human brain.

21:55.471 --> 22:03.963
There's a very extensive research effort in hundreds of places going on to probe the human brain and understand how it works.

22:03.983 --> 22:08.650
And we've already used those insights in our work in speech recognition, for example.

22:09.651 --> 22:14.458
I bought a speech recognition software a couple years ago at IBM, which I found

22:14.995 --> 22:17.598
most unsatisfactory, I have to say.

22:17.618 --> 22:26.630
To transcribe these tapes, I have this on tape.

22:28.453 --> 22:30.495
Two years is a long time in this field.

22:30.536 --> 22:34.961
The software today and two years ago is quite different.

22:35.162 --> 22:37.485
There are three main speech recognition programs.

22:37.505 --> 22:43.753
There's MIND, the one that came from my company, Kurzweil Applied Intelligence, which is now the Dictation Division of Learnout and House Feet.

22:44.442 --> 22:47.706
I sold that company to on Husby a year and a half ago.

22:48.867 --> 22:49.527
What's that called?

22:49.548 --> 22:52.090
Is that something that you can load into a regular computer?

22:52.110 --> 22:53.772
Yeah, it's a competitor to IBM Beer Voice.

22:54.373 --> 22:57.997
It's Voice Express, and I used it to dictate the book, actually.

22:58.017 --> 22:59.098
So you dictated the book?

22:59.118 --> 22:59.779
Most of it, yeah.

23:01.661 --> 23:02.001
All right.

23:02.021 --> 23:02.742
Voice Express?

23:02.942 --> 23:08.388
Yeah, there's no E. Voice Express, X, P-R-E-S-S.

23:09.589 --> 23:12.272
And we can talk to it like this, and it will... Right.

23:12.488 --> 23:15.151
It's not like this that I have to talk?

23:15.171 --> 23:15.572
No.

23:17.294 --> 23:20.118
All the speech recognition's gone beyond that barrier like a year ago.

23:21.740 --> 23:25.404
And the other competitors are Dragon and IBM.

23:27.066 --> 23:31.832
They've all come a long way in the last year, even.

23:31.852 --> 23:31.993
Good.

23:32.013 --> 23:39.542
Well, what I'm hopeful is that at some point you'll have a voice recognition that I could take a tape like this and it could actually do the give and take.

23:40.231 --> 23:45.418
Would I have to train this thing for several hours just to pick up my voice?

23:45.718 --> 23:49.363
Wouldn't it be nice if... Well, you train it for about 40 minutes.

23:49.383 --> 23:49.683
Yeah.

23:50.965 --> 23:52.186
You speak some sentences.

23:52.627 --> 23:55.270
In fact, they're going to be using the prologue to my book in a new version.

23:55.470 --> 23:55.891
Is that right?

23:57.653 --> 23:57.833
Yeah.

23:57.853 --> 23:57.994
Good.

23:58.014 --> 24:00.176
So you have a new version coming out soon?

24:00.617 --> 24:01.678
Oh, there's always a new version.

24:01.738 --> 24:04.141
The Voice Express Pro is the latest version.

24:04.281 --> 24:04.702
Pro, right?

24:05.763 --> 24:06.264
Good.

24:06.284 --> 24:09.428
I'm buying a new computer shortly, because everything you have is

24:10.066 --> 24:13.311
As you say, forget it.

24:13.511 --> 24:16.235
Well, it's part of the accelerating pace.

24:16.295 --> 24:21.642
I mean, people are now starting to notice the acceleration of computation, but it's been going on for a century.

24:21.702 --> 24:28.772
But it's the nature of exponential growth that people don't even notice exponential growth for a long time, and then suddenly it explodes.

24:29.774 --> 24:30.715
And that's happening now.

24:31.736 --> 24:34.600
And computers are still a million times simpler than the human brain.

24:34.661 --> 24:37.525
The human brain does a hundred trillion things at a time.

24:37.585 --> 24:39.988
Each neuron

24:40.171 --> 24:44.858
Each interneuronal connection is very slow, only does about 200 calculations per second.

24:45.679 --> 24:48.123
So 100 trillion times 200 is 20 million billion.

24:48.964 --> 24:53.171
And that's a million times faster than our fastest computers because of the massive parallelism.

24:54.353 --> 25:06.571
And that difference of a million is the difference between the rich, subtle behavior of humans and the relatively brittle behavior of computers.

25:06.651 --> 25:09.115
But that factor of a million is going to dissolve over the next

25:09.753 --> 25:10.434
20 years.

25:10.895 --> 25:15.621
By 2019, a thousand dollar computer will match the human brain in capacity.

25:16.443 --> 25:19.006
By 2030, it'll be equal to a thousand human brains.

25:19.607 --> 25:20.629
Okay, that's the hardware.

25:20.969 --> 25:29.902
I agree that just having the hardware capacity doesn't automatically give you human level intelligence, but that's where the reverse engineering of the human brain comes in.

25:30.322 --> 25:36.992
I mean, we're well down the path of probing, scanning, and reverse engineering the human brain to understand

25:37.715 --> 25:43.481
the secrets of intelligence, and then using those insights to organize these vast computational resources.

25:43.581 --> 25:45.623
When was the word computer first used?

25:45.703 --> 25:54.172
Do we know who actually... If you look at some of these old movies, they show you these big, you know, they're as big as rooms, and they call them electronic brains.

25:55.513 --> 25:58.396
I'm wondering where the word computer actually... Look at Dan Ever-Bush.

25:58.757 --> 25:59.477
He didn't call it.

26:00.298 --> 26:05.123
In that famous essay in The Atlantic, never once uses the word computer in there, all these other words.

26:05.693 --> 26:06.694
That's a good question.

26:06.774 --> 26:07.876
I'm not sure of the answer to that.

26:07.956 --> 26:08.496
I'm curious.

26:08.777 --> 26:10.159
I'd love to find it.

26:10.459 --> 26:13.082
What did Turing use?

26:13.963 --> 26:15.665
I'll check it out, but I'm sure it's not computing.

26:16.166 --> 26:16.607
Computer.

26:17.207 --> 26:19.009
I'd love to know who's credited for it.

26:19.790 --> 26:29.963
The OED isn't really... I actually should check the OED and see what they say, but I think the computer will go back earlier than the machines, you know?

26:30.449 --> 26:32.011
they just find the first reference.

26:33.012 --> 26:38.038
I think they used the term in the 50s, but I'm not sure exactly who used it first.

26:38.058 --> 26:38.799
Interesting to know.

26:39.159 --> 26:40.922
And is that a good word for it, computer?

26:43.084 --> 26:58.903
Not really, because right from that word computer comes a lot of misconceptions about the capabilities of this kind of device, because people assume that it just computes, which is to say it just calculates, and it does, it performs

26:59.761 --> 27:04.447
sort of rote, predictable sequences of calculations.

27:05.269 --> 27:15.262
So people figure, well, of course, it's very good at calculating, but you can never really think in an intuitive way, and there's something qualitatively different about what humans do and what a computer can do.

27:16.163 --> 27:18.046
Computers can only do what you program them to do.

27:18.086 --> 27:21.351
They'll never do anything surprising to their programmer.

27:22.532 --> 27:23.694
And none of that's true.

27:23.714 --> 27:26.397
I mean, there are processes going on in the human brain.

27:26.498 --> 27:28.300
I mean, it is a physical entity.

27:28.887 --> 27:34.135
And those processes can be understood and can be replicated in a non-biological mechanism.

27:35.097 --> 27:42.007
And don't call it a computer, because I think these entities are going to be, we're going to design them very differently than today's computers.

27:43.249 --> 27:56.650
They're going to be, the emphasis is going to be on pattern recognition, which is self-organizing processes, highly parallel, where information is stored as a pattern throughout a region as opposed to

27:56.984 --> 28:01.409
being stored in a tight logical data structure.

28:01.549 --> 28:03.992
But computers are really very flexible.

28:04.012 --> 28:09.718
You can emulate with a computer these chaotic processes and recreate them.

28:10.699 --> 28:20.069
Well, chaos theory is pretty central to you, to what you write here, and then you actually kind of go counter to it in any respect, too much.

28:20.089 --> 28:26.856
Well, I mean, chaos theory, so-called, which is, say, computing methods that are not

28:27.460 --> 28:40.293
predictable where solutions emerge from the interplay of millions of little processes is a better paradigm for understanding the human brain.

28:40.313 --> 28:41.975
Our brain is not logically organized.

28:42.015 --> 28:43.857
It's highly redundant.

28:45.278 --> 28:48.481
None of the neurons are individually important.

28:48.522 --> 28:50.744
Processes occur because of patterns of information.

28:52.526 --> 28:54.868
But we have a lot of paradigms already, neural nets.

28:55.490 --> 29:02.318
evolutionary algorithms, Markov models, and there are others that also have similar properties.

29:03.579 --> 29:10.587
And when we actually build our hardware in a massively parallel fashion, we'll be able to give much greater power to those methods.

29:11.869 --> 29:19.637
I remember there was a time when people were saying that the great discovery of the 20th century was the unlocking of the atom.

29:19.657 --> 29:21.419
And that's probably not the case anymore.

29:21.519 --> 29:24.703
It's probably the invention of the microchip.

29:24.987 --> 29:38.526
Uh, computation, the emergence of computation, uh, is the most powerful, it's by far the most powerful, uh, discovery, uh, although actually it was discovered in the nineteenth century.

29:38.566 --> 29:42.792
I mean, Babbage, Babbage's computer is very modern design.

29:42.832 --> 29:45.856
I think your computer isn't as the first one.

29:46.898 --> 29:47.158
Right.

29:48.139 --> 29:52.986
Uh, he called it the analytical engine.

29:53.894 --> 30:00.541
And you can recreate the world through this kind of computation.

30:01.903 --> 30:07.869
And in fact, it has infiltrated every sphere of human endeavor.

30:08.610 --> 30:09.731
My father was a musician.

30:09.751 --> 30:11.373
He died in 1970.

30:12.314 --> 30:23.226
And if you wanted to hear his multi-instrumental orchestration, he had to raise money, hire an orchestra, rent a room, write out handwritten scores, run it off on the mimeograph machine.

30:23.594 --> 30:26.598
And finally you get to hear his damn composition.

30:27.419 --> 30:31.624
Then if you wanted to change it, you'd have to dismiss the musicians and rewrite the scores, raise more money.

30:32.004 --> 30:33.787
Paying them very expensive over time.

30:33.807 --> 30:46.082
You know, now a teenager in her bedroom can hear her orchestral composition just on her bed and change it and modify it like one would edit a letter on a word processor.

30:46.102 --> 30:50.968
You predict in here that machines will be producing works of art?

30:51.944 --> 30:54.066
writing, I guess, will follow at some point.

30:54.847 --> 30:56.228
What's the point?

30:56.528 --> 31:04.256
What is the point of art produced by a machine, when art, by definition, is creative expression of a human?

31:04.316 --> 31:09.841
I mean, I don't say anyone would be interested in a painting done by a machine.

31:10.561 --> 31:12.703
Maybe I'm just a little too old-fashioned on that.

31:12.723 --> 31:19.690
I think one of the main messages of the book is that there's not going to be a clear distinction between you and a machine.

31:20.547 --> 31:25.634
machines are going to become as complex as humans.

31:25.794 --> 31:26.255
And lovable?

31:27.396 --> 31:40.874
Yes, I mean, that's... I'm not making fun, I'm just asking... No, I think that's a good question, because I think being lovable or displaying emotions, creativity, intuition, these sort of softer qualities of human beings, is the ultimate of human intelligence.

31:41.715 --> 31:46.622
It's not that... Intelligence is not being a great mathematician.

31:47.543 --> 31:49.626
The ultimate of human intelligence is...

31:50.247 --> 32:11.891
our personalities, our ability to handle emotion, uh, to be emotional, uh, to be lovable, to recognize and respond to joy and sadness and, uh... That's fine, don't worry about me, I'm just waiting for the... I'll blink if I don't know what you're gonna... No, no, that's fine.

32:11.911 --> 32:13.213
Why is it not gonna be green light there?

32:14.114 --> 32:17.217
Um... The machines own computers that stick, right?

32:18.530 --> 32:25.859
This is the ultimate in human intelligence.

32:25.879 --> 32:33.249
Those qualities require an entity that's immensely complex to achieve that level of subtlety and gentleness.

32:35.652 --> 32:47.187
Those qualities is the cutting edge of human intelligence, and it's a necessary byproduct of something that's as complex and subtle and deep and rich as a human being.

32:47.420 --> 32:53.786
as our non-biological entities achieve that level of complexity and subtlety, they will have those kinds of qualities.

32:53.946 --> 33:08.620
And at least in some measure, they will be built in man's image because that is the best source we have of creating intelligence and then surpassing it once we master its secrets.

33:09.060 --> 33:14.305
If you achieve, recreate a human-like brain, you can extend its memory a million-fold and you can make it

33:14.926 --> 33:17.709
a lot faster, and you can extend it in many ways.

33:17.729 --> 33:22.473
I mean, right now, we're stuck in a brain of only a hundred trillion connections.

33:23.294 --> 33:26.176
In the next century, there'd be no reason for our minds to stay so small.

33:26.917 --> 33:27.357
Our minds.

33:27.677 --> 33:27.778
Yeah.

33:29.179 --> 33:32.862
So does it bother you that you won't be here?

33:32.882 --> 33:36.085
Or maybe you will be here 100 years from now to see this.

33:37.666 --> 33:40.709
Do you think maybe you were born 30 years too soon or 40 years too soon?

33:41.050 --> 33:43.111
I did write a health book.

33:43.772 --> 33:44.933
I'll give you a copy of it.

33:45.402 --> 33:49.908
Because we do have to keep our carbon cell-based bodies and brains going a little bit longer.

33:52.611 --> 34:05.368
But even if I were around, it's not clear to me that you and I, even if we stayed very healthy, have the opportunity to enjoy that kind of longevity.

34:05.388 --> 34:12.557
Because if you do the mental experiment, let's say I'm sleeping and you scan my brain 20, 30,

34:13.263 --> 34:17.169
And then you reinstantiate it, and there's a new Ray Kurzweil, and he's got a body.

34:17.189 --> 34:17.910
What was that word again?

34:17.930 --> 34:18.331
You re what?

34:18.351 --> 34:19.212
Re-instantiate.

34:19.232 --> 34:21.696
Re-instantiate, okay.

34:21.716 --> 34:32.332
Now, if you were to meet the new Ray Kurzweil, you'd be convinced that this is, well, someone very much like Ray Kurzweil, because he'll act just like Ray Kurzweil.

34:32.352 --> 34:33.854
Would the new Ray Kurzweil need glasses?

34:36.478 --> 34:42.527
Well, the... Maybe that's a stupid question, but maybe the new Ray, to eliminate imperfections.

34:42.895 --> 34:45.338
Right, that would be an easy imperfection to eliminate.

34:45.358 --> 34:46.159
That would really be simple.

34:46.199 --> 34:48.482
And that would be a temptation to go down that path.

34:48.542 --> 34:54.028
We may end up throwing the baby out with the bathwater by the time we get done throwing out the quote of imperfections.

34:54.048 --> 34:56.731
I mean, that sort of engineering does lead, you know.

34:56.891 --> 34:57.993
Right, but we're doing that now.

34:58.013 --> 35:01.196
I mean, we do try to overcome imperfections.

35:01.557 --> 35:05.481
There is, in fact, the surgery that claims to overcome the need for glasses.

35:07.384 --> 35:12.109
It's more controversial, but I mean, we do apply technology to overcoming

35:12.680 --> 35:13.421
imperfections.

35:13.441 --> 35:17.728
So the new Ray Kurzweil probably would not need glasses.

35:20.271 --> 35:35.655
But now that, Ray Kurzweil being in a non-biological medium, is more of a software entity, because that mind file doesn't need to be discarded when that hardware crashes or gets ported to some new personal computer.

35:35.675 --> 35:39.260
I mean, when I go from one personal computer to another, I don't throw all my files away.

35:39.340 --> 35:41.003
I copy them.

35:41.023 --> 35:41.944
And similarly,

35:42.413 --> 35:50.582
you know, the mind files of these non-biological entities will survive the demise of the hardware substrates.

35:50.602 --> 35:51.864
Well, that's arguable, though, isn't it?

35:51.924 --> 36:00.434
I mean, one of the big... Well, it is arguable because that has not given me immortality.

36:00.474 --> 36:05.219
Because if you came to me and said, well, Ray, good news, we've successfully reinstantiated your body and brain.

36:05.660 --> 36:07.722
We don't need this old body and brain.

36:08.003 --> 36:10.125
I'd say, wait a second.

36:10.578 --> 36:11.419
Right, exactly.

36:11.579 --> 36:13.421
That reasoning is flawed.

36:15.223 --> 36:17.085
You know, good luck to that guy, but that's not me.

36:17.125 --> 36:17.746
I'm still here.

36:19.107 --> 36:27.457
So having done that mental experiment shows that my consciousness has not leaped somehow to this new entity.

36:29.158 --> 36:39.690
If you did it in one step, you kind of copied in a destructive manner the information and ported it destructively to this new person,

36:40.463 --> 36:52.621
and then you met the new person, he would say, well, I was worried about this operation, but you know, it really worked, you know, and I'm still here, and this is great, and I'm now in this much more capable body and brain, and I'm really glad I did this.

36:53.202 --> 36:57.287
Well, he's glad he did that, because he wouldn't even exist if it hadn't happened.

36:58.289 --> 37:06.481
But that's equivalent to having scanned, you know, the old Jack, copied him into the new Jack, and then destroyed the, or murdered the old Jack.

37:07.322 --> 37:08.023
Well, so,

37:10.805 --> 37:17.033
So I don't really see this as a way that I personally can gain immortality.

37:17.133 --> 37:30.911
But if you look at it from a different vantage point, which is the vantage point of sort of human civilization, these new entities do have a reality, and their reality is more of a software reality than a hardware reality.

37:32.453 --> 37:36.078
But what happens when the operating systems change?

37:36.759 --> 37:39.462
We hear today about the need to migrate

37:39.897 --> 37:40.338
data.

37:40.438 --> 37:44.963
You have these punched cards from 30 years ago that are worthless.

37:45.003 --> 37:46.425
There are no machines to read them.

37:47.006 --> 37:49.489
You have all this data on these cards, but nobody can read it.

37:49.729 --> 37:53.453
You talk about all this Viking space probe stuff that's worthless now.

37:53.513 --> 38:06.529
It's actually a real issue that we're finding that data does not have a huge longevity in terms of

38:07.268 --> 38:18.159
kind of substrate it's on, because the technology is transforming so quickly that, you know, if you have even... And wouldn't it be an irony if this is around 100 years from now, which it will be, by the way.

38:18.179 --> 38:21.322
I mean, when I ask you to sign it, it'll be an artifact.

38:21.942 --> 38:29.029
I have a collection of these artifacts, and I'm reasonably confident, you know, unless there's some... Well, you bring up a very good point.

38:29.670 --> 38:32.753
That will be around 100 years from now, and

38:32.986 --> 38:35.410
We have not solved this problem with regard to data.

38:35.470 --> 38:38.534
I mean, in theory, data can last forever, but you constantly have to port it.

38:39.215 --> 38:44.023
Because if I have, let's say, a backup tape that was done on a personal computer 10 years ago, it's not so long ago.

38:44.243 --> 38:44.744
Lots of luck.

38:45.024 --> 38:45.665
Lots of luck.

38:46.306 --> 38:46.807
I know this.

38:46.867 --> 38:56.061
In my first book, all my interviews were on these big five-inch... Yeah, find the tape drive, find the computer it ran on, the operating system, get all that stuff to actually work.

38:56.221 --> 38:58.765
And then hope the disks haven't degraded at the same time.

38:59.506 --> 39:01.930
Right, right.

39:02.686 --> 39:05.630
Information actually has to be constantly... Migrated.

39:05.650 --> 39:06.131
Migrated.

39:06.271 --> 39:06.792
Refreshed.

39:06.812 --> 39:07.873
I mean, I know all these words.

39:09.595 --> 39:11.258
This is a very interesting book I'm working on.

39:11.278 --> 39:15.924
I wonder, when I read a book like this, if I'm wasting my time, you know?

39:15.944 --> 39:23.494
I mean, here I am trying to see where we're going with print culture and machine culture and, you know, look at books.

39:23.514 --> 39:26.919
The things that we call books have changed constantly over 5,000 years.

39:27.580 --> 39:30.904
And, I mean, it's a vehicle for the knowledge, I guess, is the...

39:31.053 --> 39:31.874
Right.

39:32.115 --> 39:44.055
I mean, data does have to be migrated, and to accept that the mind of the brain and its state of an entity like this is data, it'll have to be migrated as well.

39:44.175 --> 39:48.843
But it then has a reality as software as opposed to hardware.

39:49.444 --> 39:51.146
So are these machines going to come up?

39:51.167 --> 39:53.871
Are we just going to have confidence that these machines are going to come up with

39:54.104 --> 39:56.547
strategies to preserve the data?

39:56.967 --> 40:00.812
Well, ultimately, software doesn't have to stay on one computer.

40:02.274 --> 40:05.558
I mean, it can migrate on a network.

40:05.698 --> 40:19.454
I mean, the World Wide Web is going to merge into a sort of a computing medium where computing can be done anywhere in the web, and we're moving towards that already.

40:20.615 --> 40:22.778
Things like the Sun Jenny proposal where

40:23.568 --> 40:30.558
You have a program, and suddenly, for a certain period of time, it needs 10,000 computers to work on it.

40:30.598 --> 40:35.325
You can just go out, and it'll soak up the unused computers of computers on the web.

40:36.347 --> 40:45.120
And computing will be fairly transferable from one machine to another, and you won't necessarily run your programs on your computer.

40:45.200 --> 40:46.942
They'll just kind of run out on the network.

40:47.563 --> 40:50.908
I think one major question, and I realize we're probably going into it,

40:52.120 --> 40:57.104
time that's very precious to you, but the whole concept of reading as we know it is going to disappear.

40:57.164 --> 41:01.668
We're not going to read the way we read now letters.

41:01.868 --> 41:03.650
Well, that's some decades off.

41:03.690 --> 41:05.632
I mean, you do suggest things like that.

41:05.652 --> 41:22.026
Yeah, by the end of the century, I think that's true, because once you're in another type of entity, then we already have ways of representing knowledge in computers that don't have to go through human language.

41:22.799 --> 41:33.589
Reading.

41:35.011 --> 41:44.380
But I mean, reading, which is an embodiment of written language, is not going to go away soon.

41:45.601 --> 41:50.646
As more and more of the thinking of our civilization is done on a non-biological

41:51.537 --> 41:54.560
medium, then written language will become less important.

41:54.580 --> 41:58.443
We'll have more powerful ways of transferring knowledge more quickly.

41:59.684 --> 42:09.713
I mean, right now, you have, let's say, 20 million billion calculations per second being done by human brain, 10 billion human brains.

42:11.875 --> 42:17.140
So you have a certain amount of thinking being done in a biological medium.

42:18.081 --> 42:19.182
And if you look at all of the

42:20.056 --> 42:23.620
So computation being done on computers, it's a very trivial fraction of that.

42:24.541 --> 42:40.379
However, that non-biological computation, which is going to become more complex and more chaotic and more intelligent, but the quantity of it is going to grow exponentially, whereas the quantity of thinking being done in the biological medium is basically flat.

42:40.699 --> 42:49.489
So I've been asked to participate in a seminar next year at the American Library Association in Chicago, and the subject is

42:49.790 --> 42:56.741
Are all libraries going to be museums and are all books, every book, going to be objects?

42:56.941 --> 42:59.044
Yeah, it's just a question of how quickly.

42:59.064 --> 43:00.667
And you think that's probably the case?

43:01.348 --> 43:02.009
Oh, absolutely.

43:02.029 --> 43:13.246
Yeah, I mean, one could argue about the time frame, but it's not long.

43:14.128 --> 43:17.012
I would say ten years.

43:18.376 --> 43:24.666
Certainly 15, the majority of reading will be done not on paper, probably 10 years.

43:25.467 --> 43:36.726
You get out to 20 years and reading on paper will be relatively rare and will have reported most of the paper information to electronic form.

43:37.747 --> 43:44.518
And reading on electronic displays will not be like it is today, which is basically not satisfactory for sustained reading.

43:44.903 --> 43:54.572
But that problem, I mean, it's already been solved in laboratories, and there's a certain amount of time for these technologies to migrate out from laboratories into the real world.

43:54.592 --> 44:00.998
But certainly ten years from now, you'll have a device about the size of your pad, you know, maybe a little bit larger screen.

44:01.078 --> 44:02.399
You'll be doing most of your reading on that.

44:03.721 --> 44:08.085
And, you know, all these paper documents have to get scanned in.

44:08.185 --> 44:11.468
Of course, most of them being produced now exist electronically in one form or another.

44:12.275 --> 44:20.766
Just on the research level, I'm wondering about works of art, literary things, poetry, novels.

44:20.786 --> 44:23.510
I still wonder if there's a place for this kind of expression.

44:24.211 --> 44:28.877
Well, a book is a nice physical artifact that's an artwork, and people will continue to appreciate it.

44:30.760 --> 44:35.346
You know, of course, I mean, I talk about technology reaching the stage of antiquity,

44:36.018 --> 44:41.624
We still like mechanical typewriters, horses and buggies, vinyl records, harpsichords.

44:41.644 --> 44:42.525
I mean, they don't disappear.

44:42.585 --> 44:48.191
They're nice artifacts, and books have a long, rich history, and people will prize physical books.

44:48.331 --> 44:52.515
But that doesn't mean that the vast majority of reading won't be done on a tarp.

44:52.535 --> 44:56.459
Do you shave with an electric razor, or do you use a regular razor?

44:56.479 --> 44:59.463
I use the Mach 3 Gillette.

44:59.483 --> 44:59.943
Yeah, I do too.

45:00.023 --> 45:00.283
Why?

45:00.844 --> 45:01.385
Because it's better.

45:01.765 --> 45:03.747
Well, it's a very good technology.

45:04.621 --> 45:06.403
I spent hundreds of millions of dollars developing that.

45:07.424 --> 45:12.209
But there are some things that are superior, though, it seems to me.

45:12.229 --> 45:16.894
You know, the electric razor was supposed to mean the end of the world.

45:16.914 --> 45:19.196
Well, Mach 3 is probably the most advanced technology.

45:19.216 --> 45:20.578
I mean, the most money is spent on it.

45:20.638 --> 45:23.261
It's not a primitive technology.

45:23.281 --> 45:25.383
I use it myself, and it's wonderful.

45:25.403 --> 45:26.945
One pass.

45:27.605 --> 45:29.708
We could talk all day.

45:29.728 --> 45:30.368
This is good stuff.

45:30.769 --> 45:32.991
I think, you know, an hour is good for...

45:33.595 --> 45:34.977
Would you sign this for me?

45:35.137 --> 45:39.343
Sure, I'd be happy to.

45:39.363 --> 45:42.187
You don't write in the traditional manner you dictate, is that right?

45:43.909 --> 45:47.013
Right, but I'm still creating written text.

45:47.894 --> 45:49.196
I do have another question for you.

45:49.216 --> 45:54.623
Is the whole concept of a document a sacred document pass?

45:54.643 --> 45:57.587
Did you see that piece in the New York Times last week?

45:57.607 --> 46:01.813
The heroic efforts that are being undertaken to

46:02.283 --> 46:10.331
preserved with modern technology, the Declaration of Independence and the Constitution, our foundation documents.

46:10.351 --> 46:14.875
Why isn't a copy, in that sense, satisfactory?

46:15.176 --> 46:23.103
Well, the copies are satisfactory for lots of purposes, but there's only one original.

46:23.904 --> 46:25.446
That's right.

46:25.466 --> 46:26.687
You just said a very interesting thing.

46:26.707 --> 46:27.608
There's only one original.

46:27.788 --> 46:30.771
Is that whole concept about to disappear?

46:31.257 --> 46:32.979
Will there always be an original?

46:33.400 --> 46:37.266
It doesn't have to be a declaration of independence or a constitution?

46:37.286 --> 46:38.427
Well, it's just a distinction.

46:39.048 --> 46:40.611
It may be a distinction without a difference.

46:42.153 --> 46:44.696
I mean, our copying technologies, in fact, are imperfect.

46:46.920 --> 47:00.960
The nature of technology, I mean, technology does not spring from labor into creation with perfect capabilities and qualities from day one.

47:01.548 --> 47:03.330
In fact, it's not the nature of technology.

47:03.350 --> 47:07.775
Technology emerges very imperfect, and very gradually gets better and better.

47:08.956 --> 47:15.363
So, I mean, generally in artificial intelligence, when something's first introduced, people say, well, that's not a big deal, because it doesn't work, like speech recognition.

47:16.024 --> 47:18.046
It's a lot of hype, but, you know, you try it out, and it doesn't work.

47:18.567 --> 47:20.509
It gradually gets better and better and better.

47:20.529 --> 47:22.170
Finally, it works, and you say, well, that's not a big deal.

47:22.190 --> 47:23.672
We've been talking about that for, you know, ten years.

47:23.712 --> 47:24.633
Well, it'll be very interesting.

47:25.054 --> 47:30.019
I will have had a... So copying technologies, I mean, our copies are pretty imperfect, however,

47:30.792 --> 47:39.143
I actually have got these oil paintings recently that are computer major copies of Masters.

47:40.525 --> 47:43.069
And they're not perfect, but they're pretty damn good.

47:44.070 --> 47:47.134
But, you know, our copying technologies can get better and better.

47:47.374 --> 47:50.218
These old documents are three-dimensional documents.

47:50.258 --> 47:57.508
Why would somebody like Bill Gates pay $30 million for the Codex Western?

47:58.501 --> 48:00.604
when he could have a perfect digital copy?

48:00.945 --> 48:02.847
Why is it necessary?

48:02.927 --> 48:04.930
I don't think there's any intellectual reason for it.

48:05.832 --> 48:17.789
There's just a distinction to being that there's only one original, and so supply and demand has a high value.

48:19.712 --> 48:21.574
Will that kind of thinking continue, do you think?

48:21.594 --> 48:22.716
Or who knows, right?

48:23.577 --> 48:28.204
Well, I think it's, for example, these old painting copies,

48:28.488 --> 48:29.710
It's a computer and a laser.

48:29.750 --> 48:32.153
It creates a three-dimensional copy.

48:33.494 --> 48:36.558
And it's a very good technology.

48:36.578 --> 48:38.000
So even the brushstrokes are what I'm thinking?

48:38.020 --> 48:38.200
Oh, yeah.

48:38.220 --> 48:40.043
You can see the brushstrokes and feel them.

48:40.063 --> 48:42.245
I mean, it's a three-dimensional reproduction.

48:42.266 --> 48:45.790
And there is a question there.

48:45.810 --> 48:47.292
Does that devalue the originals?

48:47.312 --> 48:50.516
Well, it does, because it used to be only the original really looked like the original.

48:50.596 --> 48:52.038
The copies really were inferior.

48:52.999 --> 48:53.480
I'm not so sure.

48:53.500 --> 48:56.123
I don't think it devalues the original.

48:56.163 --> 48:56.824
You think it does?

48:58.424 --> 48:59.045
Probably not.

49:00.066 --> 49:12.739
Why would somebody, and this person in my view is a fool, but why would somebody spend $250,000 for the fake pearls once worn by Jackie Onassis, which you can buy at retail for $40?

49:12.919 --> 49:15.482
Because there is some sort of context there.

49:15.562 --> 49:27.655
If this is the original by Monet or whomever, I still think it has that resonance to it of having been created by the artist.

49:27.955 --> 49:31.639
It's certainly something I can write about.

49:31.659 --> 49:43.050
People have talked about archiving the web, because it's an important historical, socio-historical archive of the state of our civilization, at a particular point in time.

49:43.311 --> 49:48.416
It might be very interesting, in the year 2015, to look back and say, well, what was on the web on February 12, 1999?

49:49.977 --> 49:57.405
But it's actually very difficult to do that, because the web is not just a bunch or billions of static pages.

49:58.162 --> 50:07.310
Lots of these pages are, in fact, windows into massive databases where information is kind of computed on the fly.

50:08.871 --> 50:15.677
On a lot of websites, there's streaming video and audio information, and there's no way you could archive all that.

50:16.578 --> 50:20.121
I mean, if, for example, one web page was... There's no way you could archive it.

50:20.141 --> 50:20.262
Right.

50:20.282 --> 50:26.447
If a web page is an entry into a database, you can't

50:26.832 --> 50:28.134
just copy that database.

50:28.154 --> 50:29.315
It wouldn't even allow you to do that.

50:29.916 --> 50:35.644
You can maybe look up certain little pieces of information, but behind that is this massive database.

50:35.684 --> 50:42.272
Increasingly, webpages are not the sort of static pages that you could just copy like that.

50:42.292 --> 50:42.893
Do you read novels?

50:44.555 --> 50:45.597
I have, unfortunately.

50:47.639 --> 50:53.447
I do need some.

50:53.832 --> 50:54.593
It's a novelist.

50:54.613 --> 50:55.395
Is that right?

50:55.415 --> 50:56.216
Alan Kurzweil.

50:56.236 --> 50:56.737
Oh, sure.

50:56.797 --> 50:57.799
Case of curiosity.

50:57.819 --> 50:59.522
Yep, I've interviewed him.

50:59.542 --> 50:59.943
Young man.

51:00.484 --> 51:01.145
I like that book.

51:01.807 --> 51:04.932
It had an antiquarian texture to it, that book.

51:04.952 --> 51:08.078
It's about a... Yeah, exactly.

